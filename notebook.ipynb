{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8d62ab",
   "metadata": {},
   "source": [
    "# Retail Sales Forecasting using the M5 dataset with Granite Time Series - Few-shot finetuning, evaluation, and visualization\n",
    "\n",
    "In this tutorial, we will explore [timeseries forecasting](https://www.ibm.com/think/insights/time-series-forecasting) using the [IBM Granite Timeseries model](https://ibm.com/granite) to predict retail sales. We will cover key techniques such as few-shot forecasting and fine-tuning. We are using  [M5 datasets](https://drive.google.com/drive/folders/1D6EWdVSaOtrP1LEFh1REjI3vej6iUS_4?usp=sharing) from the official M-Competitions [repository](https://github.com/Mcompetitions/M5-methods) to forecast future sales aggregated by state. The aim of this recipe is to showcase how to use a pre-trained time series foundation model for multivariate forecasting and explores various features available with Granite Time Series Foundation Models.\n",
    "\n",
    "This recipe uses TinyTimeMixers (TTMs), which are compact pre-trained models for Multivariate Time-Series Forecasting, open-sourced by IBM Research. With less than 1 Million parameters, TTM introduces the notion of the first-ever \"tiny\" pre-trained models for Time-Series Forecasting. TTM outperforms several popular benchmarks demanding billions of parameters in zero-shot and few-shot forecasting and can easily be fine-tuned for multivariate forecasts.\n",
    "\n",
    "## Setting Up\n",
    "\n",
    "### Install the TSFM Library\n",
    "\n",
    "The [granite-tsfm library](https://github.com/ibm-granite/granite-tsfm) provides utilities for working with Time Series Foundation Models (TSFM). Here we retrieve and install the latest version of the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8772bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git (from granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git)\n",
      "  Cloning https://github.com/ibm-granite/granite-tsfm.git to /private/var/folders/t7/xsc0cc9n5qnfsv5glqn6wzq40000gn/T/pip-install-4od4fevl/granite-tsfm_7a2783e2bf3d48c4ba8f223afb84d211\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite/granite-tsfm.git /private/var/folders/t7/xsc0cc9n5qnfsv5glqn6wzq40000gn/T/pip-install-4od4fevl/granite-tsfm_7a2783e2bf3d48c4ba8f223afb84d211\n",
      "  Resolved https://github.com/ibm-granite/granite-tsfm.git to commit 66a368f93427ee6b35832ab733727e5ffbb03c23\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=2.2.0 in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.6.1)\n",
      "Requirement already satisfied: transformers>=4.38.0 in ./.venv/lib/python3.11/site-packages (from transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.49.0)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.3.2)\n",
      "Requirement already satisfied: deprecated in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.2.18)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.19 in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.26.20)\n",
      "Requirement already satisfied: numpy<2 in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.26.4)\n",
      "Requirement already satisfied: jupyter in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.1.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.10.0)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (8.1.5)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.0.0)\n",
      "Requirement already satisfied: kaleido in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.2.1)\n",
      "Requirement already satisfied: tensorboard in ./.venv/lib/python3.11/site-packages (from granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas>=2.2.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=2.2.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=2.2.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2025.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.29.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.11/site-packages (from transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in ./.venv/lib/python3.11/site-packages (from transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in ./.venv/lib/python3.11/site-packages (from transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.4.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.11/site-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.11/site-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.11.13)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from deprecated->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.17.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.11/site-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.11/site-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.11/site-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.venv/lib/python3.11/site-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.venv/lib/python3.11/site-packages (from ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.0.13)\n",
      "Requirement already satisfied: notebook in ./.venv/lib/python3.11/site-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (7.3.2)\n",
      "Requirement already satisfied: jupyter-console in ./.venv/lib/python3.11/site-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in ./.venv/lib/python3.11/site-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.11/site-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.29.5)\n",
      "Requirement already satisfied: jupyterlab in ./.venv/lib/python3.11/site-packages (from jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.3.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.2.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.11/site-packages (from plotly->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.28.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (75.8.0)\n",
      "Requirement already satisfied: six>1.9 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.1.3)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.12.2)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers>=4.38.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2025.1.31)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]>=4.38.0->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.0.2)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.8.12)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.11/site-packages (from ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.4.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./.venv/lib/python3.11/site-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in ./.venv/lib/python3.11/site-packages (from jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./.venv/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.11/site-packages (from nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.5.1)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.11/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.4.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./.venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in ./.venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (21.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.23.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./.venv/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.2.1)\n",
      "Requirement already satisfied: rfc3339-validator in ./.venv/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./.venv/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (0.1.1)\n",
      "Requirement already satisfied: fqdn in ./.venv/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./.venv/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./.venv/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (3.0.0)\n",
      "Requirement already satisfied: uri-template in ./.venv/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./.venv/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./.venv/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./.venv/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./.venv/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->granite-tsfm@ git+https://github.com/ibm-granite/granite-tsfm.git->granite-tsfm[notebooks]@ git+https://github.com/ibm-granite/granite-tsfm.git) (2.9.0.20241206)\n"
     ]
    }
   ],
   "source": [
    "# Install the tsfm library\n",
    "! pip install \"granite-tsfm[notebooks] @ git+https://github.com/ibm-granite/granite-tsfm.git\" -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b62e9",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "From `tsfm_public`, we use the TinyTimeMixer model, forecasting pipeline, and plotting function. We also leverage a few components for the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5230e2-b163-4d1a-a715-239b9190cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import Subset\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "\n",
    "from tsfm_public import (\n",
    "    ForecastDFDataset,\n",
    "    TimeSeriesPreprocessor,\n",
    "    TinyTimeMixerForPrediction,\n",
    "    TrackingCallback,\n",
    "    count_parameters,\n",
    ")\n",
    "from tsfm_public.toolkit.lr_finder import optimal_lr_finder\n",
    "from tsfm_public.toolkit.time_series_preprocessor import prepare_data_splits\n",
    "from tsfm_public.toolkit.util import select_by_timestamp\n",
    "from tsfm_public.toolkit.visualization import plot_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcdc5f",
   "metadata": {},
   "source": [
    "### Specify configuration variables\n",
    "\n",
    "The forecast length is specified as well as the context length (in time steps) which is set to match the pretrained model. Additionally, we declare the Granite Time Series Model and the specific revision we are targeting.\n",
    "\n",
    "The granite-timeseries TTM R2 card has several different revisions of the model available for various context lengths and prediction lengths. In this example we will be working with daily data, so we choose a model suitable for that resolution -- 90 days of history to forecast the next 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d39d6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_length = 28\n",
    "context_length = 90\n",
    "\n",
    "TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r2\"\n",
    "REVISION = \"90-30-ft-l1-r2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd3add-8948-453e-bd1c-13977979ecee",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "As mentioned in the introduction, this notebook makes use of the [M5 datasets](https://drive.google.com/drive/folders/1D6EWdVSaOtrP1LEFh1REjI3vej6iUS_4?usp=sharing) from the official M-Competitions [repository](https://github.com/Mcompetitions/M5-methods). \n",
    "\n",
    "\n",
    "The original data includes hierarchy and product information, for this example we aggregate the sales by state into three separate time series. The code for downloading the datasets and preparing them is available in `M5_retail_data_prep.py`. Here, we simply run the `prepare_data()` function to save the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37127509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9684 sha256=acfa2c021398b56e39aa59057f3f7395586ab0ebed99b12fc66243911063406f\n",
      "  Stored in directory: /Users/joesepi/Library/Caches/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install wget\n",
    "import wget\n",
    "url = 'https://raw.githubusercontent.com/ibm-granite-community/granite-timeseries-cookbook/refs/heads/main/recipes/Time_Series/Bike_Sharing_Finetuning_with_Exogenous.ipynb'\n",
    "M5_retail_data_prep = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "223ebbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-27337:t-8601880640:M5_retail_data_prep.py:prepare_data:Temporary folder already exists, assuming data already downloaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the prepared M5 data to m5_for_state_level_forecasting.csv.gz.\n"
     ]
    }
   ],
   "source": [
    "from M5_retail_data_prep import prepare_data\n",
    "prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce78a17",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "\n",
    "We parse the CSV into a pandas dataframe and ensure the timestamp column is a UTC datetime and drop two unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa99c39c-04d4-4df6-8bfe-500d4c973b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>wm_yr_wk_sin</th>\n",
       "      <th>wday_sin</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>enc_state_id_mean</th>\n",
       "      <th>enc_state_id_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>14195</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14989.831155</td>\n",
       "      <td>3257.223505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX</td>\n",
       "      <td>9438</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9879.250392</td>\n",
       "      <td>1964.928938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WI</td>\n",
       "      <td>8998</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9472.480920</td>\n",
       "      <td>2563.314535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>13805</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14989.831155</td>\n",
       "      <td>3257.223505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX</td>\n",
       "      <td>9630</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>noevent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9879.250392</td>\n",
       "      <td>1964.928938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_id  sales       date  wm_yr_wk  wday  month  year  snap_CA  snap_TX  \\\n",
       "0       CA  14195 2011-01-29         0     0      0  2011        0        0   \n",
       "1       TX   9438 2011-01-29         0     0      0  2011        0        0   \n",
       "2       WI   8998 2011-01-29         0     0      0  2011        0        0   \n",
       "3       CA  13805 2011-01-30         0     1      0  2011        0        0   \n",
       "4       TX   9630 2011-01-30         0     1      0  2011        0        0   \n",
       "\n",
       "   snap_WI event_name_1 event_type_1 event_name_2 event_type_2  wm_yr_wk_sin  \\\n",
       "0        0      noevent      noevent      noevent      noevent           0.0   \n",
       "1        0      noevent      noevent      noevent      noevent           0.0   \n",
       "2        0      noevent      noevent      noevent      noevent           0.0   \n",
       "3        0      noevent      noevent      noevent      noevent           0.0   \n",
       "4        0      noevent      noevent      noevent      noevent           0.0   \n",
       "\n",
       "   wday_sin  month_sin  enc_state_id_mean  enc_state_id_std  \n",
       "0  0.000000        0.0       14989.831155       3257.223505  \n",
       "1  0.000000        0.0        9879.250392       1964.928938  \n",
       "2  0.000000        0.0        9472.480920       2563.314535  \n",
       "3  0.781831        0.0       14989.831155       3257.223505  \n",
       "4  0.781831        0.0        9879.250392       1964.928938  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"m5_for_state_level_forecasting.csv.gz\"\n",
    "\n",
    "data = pd.read_csv(data_path, parse_dates=[\"date\"]).drop(columns=[\"d\", \"weekday\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c127c",
   "metadata": {},
   "source": [
    "Next, we must clean up the columns in our data and declare the names of the timestamp column, the target column to be predicted as well as the categorical column used to aggregate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "075d0d68-bd82-47d1-afab-fd4e7a3ffe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(data.columns)\n",
    "[cols.remove(c) for c in [\"date\", \"sales\", \"state_id\"]]\n",
    "cols\n",
    "\n",
    "column_specifiers = {\n",
    "    \"timestamp_column\": \"date\",\n",
    "    \"id_columns\": [\"state_id\"],\n",
    "    \"target_columns\": [\"sales\"],\n",
    "    \"control_columns\": cols,\n",
    "    \"static_categorical_columns\": [\"state_id\"],\n",
    "    \"categorical_columns\": [\n",
    "        \"event_name_1\",\n",
    "        \"event_type_1\",\n",
    "        \"event_name_2\",\n",
    "        \"event_type_2\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011a6cc",
   "metadata": {},
   "source": [
    "### Train the Preprocessor\n",
    "\n",
    "The preprocessor is trained on the training portion of the input data to learn the scaling factors. The scaling will be applied when we use the preprocess method of the time series preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aa71ff5-f6ba-4c51-8f4f-9a12438845fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp = TimeSeriesPreprocessor(\n",
    "    **column_specifiers,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_length,\n",
    "    scaling=True,\n",
    "    encode_categorical=True,\n",
    "    scaler_type=\"standard\",\n",
    ")\n",
    "\n",
    "df_train = select_by_timestamp(\n",
    "    data, timestamp_column=column_specifiers[\"timestamp_column\"], end_timestamp=\"2016-05-23\"\n",
    ")\n",
    "\n",
    "trained_tsp = tsp.train(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543737f6",
   "metadata": {},
   "source": [
    "## Finetune the model\n",
    "\n",
    "Now we will focus on fine-tuning the pretrained model. We use the same data splits we defined above, but now include extra columns during the fine-tuning process.\n",
    "\n",
    "### Preparing the data for fine-tuning\n",
    "\n",
    "We split the data into training, validation, and test sets. The training set is used to train the model, while the test set is used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5340414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_params = {\"train\": [0, 0.5], \"valid\": [0.5, 0.75], \"test\": [0.75, 1.0]}\n",
    "\n",
    "train_data, valid_data, test_data = prepare_data_splits(\n",
    "    data, id_columns=column_specifiers[\"id_columns\"], split_config=split_params, context_length=context_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6279d1",
   "metadata": {},
   "source": [
    "Here we will construct the torch dataset because we cant pass panda dataframes using our torch dataset class specifically designed for forecasting usecases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665fa12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_token = tsp.get_frequency_token(tsp.freq)\n",
    "\n",
    "dataset_params = column_specifiers.copy()\n",
    "dataset_params[\"frequency_token\"] = frequency_token\n",
    "dataset_params[\"context_length\"] = context_length\n",
    "dataset_params[\"prediction_length\"] = forecast_length\n",
    "\n",
    "\n",
    "train_dataset = ForecastDFDataset(tsp.preprocess(train_data), **dataset_params)\n",
    "valid_dataset = ForecastDFDataset(tsp.preprocess(valid_data), **dataset_params)\n",
    "test_dataset = ForecastDFDataset(tsp.preprocess(test_data), **dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f9cce",
   "metadata": {},
   "source": [
    "Now let's take a smaller sample from the torch datasets produced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500fc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2601, 520, 1395, 348)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20% training data (few-shot finetuning)\n",
    "n_train_all = len(train_dataset)\n",
    "train_index = np.random.permutation(n_train_all)[: int(0.2 * n_train_all)]\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "\n",
    "# 25% validation data\n",
    "n_valid_all = len(valid_dataset)\n",
    "valid_index = np.random.permutation(n_valid_all)[: int(0.25 * n_valid_all)]\n",
    "valid_dataset = Subset(valid_dataset, valid_index)\n",
    "\n",
    "n_train_all, len(train_dataset), n_valid_all, len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22337b16-1e82-494a-bce8-8c49b9758cb2",
   "metadata": {},
   "source": [
    "### Load the model for fine-tuning\n",
    "\n",
    "We must first load the TTM model available on HuggingFace using the model and revision set above. We have three target channels and several exogenous channels in this example and set configuration appropriately take this into accounts. Note that we also enable channel mixing in the decoder and forecast channel mising. This allows the decoder to be tuned to capture interactions between the channels as well as adjust the forecasts based on interactions with the exogenous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12c77656-42d4-4b51-a6c3-a4245a794cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TinyTimeMixerForPrediction were not initialized from the model checkpoint at ibm-granite/granite-timeseries-ttm-r2 and are newly initialized: ['decoder.decoder_block.mixers.0.channel_feature_mixer.gating_block.attn_layer.bias', 'decoder.decoder_block.mixers.0.channel_feature_mixer.gating_block.attn_layer.weight', 'decoder.decoder_block.mixers.0.channel_feature_mixer.mlp.fc1.bias', 'decoder.decoder_block.mixers.0.channel_feature_mixer.mlp.fc1.weight', 'decoder.decoder_block.mixers.0.channel_feature_mixer.mlp.fc2.bias', 'decoder.decoder_block.mixers.0.channel_feature_mixer.mlp.fc2.weight', 'decoder.decoder_block.mixers.0.channel_feature_mixer.norm.norm.bias', 'decoder.decoder_block.mixers.0.channel_feature_mixer.norm.norm.weight', 'decoder.decoder_block.mixers.1.channel_feature_mixer.gating_block.attn_layer.bias', 'decoder.decoder_block.mixers.1.channel_feature_mixer.gating_block.attn_layer.weight', 'decoder.decoder_block.mixers.1.channel_feature_mixer.mlp.fc1.bias', 'decoder.decoder_block.mixers.1.channel_feature_mixer.mlp.fc1.weight', 'decoder.decoder_block.mixers.1.channel_feature_mixer.mlp.fc2.bias', 'decoder.decoder_block.mixers.1.channel_feature_mixer.mlp.fc2.weight', 'decoder.decoder_block.mixers.1.channel_feature_mixer.norm.norm.bias', 'decoder.decoder_block.mixers.1.channel_feature_mixer.norm.norm.weight', 'decoder.decoder_block.mixers.2.channel_feature_mixer.gating_block.attn_layer.bias', 'decoder.decoder_block.mixers.2.channel_feature_mixer.gating_block.attn_layer.weight', 'decoder.decoder_block.mixers.2.channel_feature_mixer.mlp.fc1.bias', 'decoder.decoder_block.mixers.2.channel_feature_mixer.mlp.fc1.weight', 'decoder.decoder_block.mixers.2.channel_feature_mixer.mlp.fc2.bias', 'decoder.decoder_block.mixers.2.channel_feature_mixer.mlp.fc2.weight', 'decoder.decoder_block.mixers.2.channel_feature_mixer.norm.norm.bias', 'decoder.decoder_block.mixers.2.channel_feature_mixer.norm.norm.weight', 'decoder.decoder_block.mixers.3.channel_feature_mixer.gating_block.attn_layer.bias', 'decoder.decoder_block.mixers.3.channel_feature_mixer.gating_block.attn_layer.weight', 'decoder.decoder_block.mixers.3.channel_feature_mixer.mlp.fc1.bias', 'decoder.decoder_block.mixers.3.channel_feature_mixer.mlp.fc1.weight', 'decoder.decoder_block.mixers.3.channel_feature_mixer.mlp.fc2.bias', 'decoder.decoder_block.mixers.3.channel_feature_mixer.mlp.fc2.weight', 'decoder.decoder_block.mixers.3.channel_feature_mixer.norm.norm.bias', 'decoder.decoder_block.mixers.3.channel_feature_mixer.norm.norm.weight', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.gating_block.attn_layer.bias', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.gating_block.attn_layer.weight', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.mlp.fc1.bias', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.mlp.fc1.weight', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.mlp.fc2.bias', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.mlp.fc2.weight', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.norm.norm.bias', 'head.fcm_block.exog_mixer.mixers.0.feature_mixer.norm.norm.weight', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.gating_block.attn_layer.bias', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.gating_block.attn_layer.weight', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.mlp.fc1.bias', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.mlp.fc1.weight', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.mlp.fc2.bias', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.mlp.fc2.weight', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.norm.norm.bias', 'head.fcm_block.exog_mixer.mixers.0.patch_mixer.norm.norm.weight', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.gating_block.attn_layer.bias', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.gating_block.attn_layer.weight', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.mlp.fc1.bias', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.mlp.fc1.weight', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.mlp.fc2.bias', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.mlp.fc2.weight', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.norm.norm.bias', 'head.fcm_block.exog_mixer.mixers.1.feature_mixer.norm.norm.weight', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.gating_block.attn_layer.bias', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.gating_block.attn_layer.weight', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.mlp.fc1.bias', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.mlp.fc1.weight', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.mlp.fc2.bias', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.mlp.fc2.weight', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.norm.norm.bias', 'head.fcm_block.exog_mixer.mixers.1.patch_mixer.norm.norm.weight', 'head.fcm_block.fcm_embedding.bias', 'head.fcm_block.fcm_embedding.weight', 'head.fcm_block.fcm_gating_block.attn_layer.bias', 'head.fcm_block.fcm_gating_block.attn_layer.weight', 'head.fcm_block.mlp.bias', 'head.fcm_block.mlp.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "finetune_forecast_model = TinyTimeMixerForPrediction.from_pretrained(\n",
    "    TTM_MODEL_PATH,\n",
    "    revision=REVISION,\n",
    "    context_length=context_length,\n",
    "    prediction_filter_length=forecast_length,\n",
    "    num_input_channels=tsp.num_input_channels,\n",
    "    decoder_mode=\"mix_channel\",  # exog:  set to mix_channel for mixing channels in history\n",
    "    prediction_channel_indices=tsp.prediction_channel_indices,\n",
    "    exogenous_channel_indices=tsp.exogenous_channel_indices,\n",
    "    fcm_context_length=1,  # exog: indicates lag length to use in the exog fusion. for Ex. if today sales can get affected by discount on +/- 2 days, mention 2\n",
    "    fcm_use_mixer=True,  # exog: Try true (1st option) or false\n",
    "    fcm_mix_layers=2,  # exog: Number of layers for exog mixing\n",
    "    enable_forecast_channel_mixing=True,  # exog: set true for exog mixing\n",
    "    fcm_prepend_past=True,  # exog: set true to include lag from history during exog infusion.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf182c",
   "metadata": {},
   "source": [
    "### Optional: Freeze the TTM Backbone\n",
    "\n",
    "During fine-tuning we freeze the backbone and focus on tuning only the parameters in the decoder. This reduces the overall number of parameters being tuned and maintains what the encoder learned during pretraining. For this notebook, we will keep the TTM backbone unfrozen, but we've included the code for users who may want to experiment with freezing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d168ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_backbone = False\n",
    "if freeze_backbone:\n",
    "    print(\n",
    "        \"Number of params before freezing backbone\",\n",
    "        count_parameters(finetune_forecast_model),\n",
    "    )\n",
    "\n",
    "    # Freeze the backbone of the model\n",
    "    for param in finetune_forecast_model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Count params\n",
    "    print(\n",
    "        \"Number of params after freezing the backbone\",\n",
    "        count_parameters(finetune_forecast_model),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d1996",
   "metadata": {},
   "source": [
    "### Set up a Trainer for Fine-tuning\n",
    "\n",
    "Configure a Trainer for use in fine-tuning and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e625c63-0dff-4c13-85af-22e7848b5ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-27337:t-8601880640:lr_finder.py:optimal_lr_finder:LR Finder: Running learning rate (LR) finder algorithm. If the suggested LR is very low, we suggest setting the LR manually.\n",
      "INFO:p-27337:t-8601880640:lr_finder.py:optimal_lr_finder:LR Finder: Using CPU.\n",
      "INFO:p-27337:t-8601880640:lr_finder.py:optimal_lr_finder:LR Finder: Suggested learning rate = 0.0005214008287999684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMAL SUGGESTED LEARNING RATE = 0.0005214008287999684\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Ideally, we need more epochs (try offline preferably in a gpu for faster computation)\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate, finetune_forecast_model = optimal_lr_finder(\n",
    "    finetune_forecast_model,\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    enable_prefix_tuning=True,\n",
    ")\n",
    "print(\"OPTIMAL SUGGESTED LEARNING RATE =\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4049d",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "Here we train the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39944f77-4bb7-4066-b5a7-6f3a76cb1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learning rate = 0.0005214008287999684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-93600:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93606:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93607:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93647:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [396/450 43:15 < 05:55, 0.15 it/s, Epoch 44/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.579633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>0.522812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.470904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.471321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.493303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.449960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.440951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>0.460977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.437332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.438951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.429524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.441839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.418300</td>\n",
       "      <td>0.407543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.414472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.406349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>0.405966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.401125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.358900</td>\n",
       "      <td>0.402879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.381604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.383226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.390524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.407861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>0.391628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.376897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.401745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.387027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.398093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.377837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.325100</td>\n",
       "      <td>0.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.381130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.393596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.385198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.393439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.373150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.388164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.390092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>0.395602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.384722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.380189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.382833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.386433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.387690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.386296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.388482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-93696:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93722:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93743:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93745:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93804:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93805:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93806:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-93807:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94068:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94069:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94070:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94071:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94155:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94162:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94163:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94164:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94249:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94250:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94251:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94252:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94306:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94312:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94317:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94357:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94424:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94460:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94473:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94474:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94521:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94522:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94523:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94524:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94609:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94613:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94614:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94615:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94695:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94701:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94702:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94705:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94794:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94796:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94797:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94798:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94844:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94850:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94853:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94893:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94948:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94985:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94989:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-94990:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95034:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95041:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95042:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95045:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95130:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95131:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95132:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95133:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95215:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95216:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95217:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95220:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95346:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95353:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95356:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95358:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95440:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95445:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95493:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95494:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95579:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95616:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95618:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95626:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95669:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95670:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95671:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95672:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95768:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95773:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95775:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95812:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95859:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95862:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95863:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95864:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95954:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95959:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95960:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-95962:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96028:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96033:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96076:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96077:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96162:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96171:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96175:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96176:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96235:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96249:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96250:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96252:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96371:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96376:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96377:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96417:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96485:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96502:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96503:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96505:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96593:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96598:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96599:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96600:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96672:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96722:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96723:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96724:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96835:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96840:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96847:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96854:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96929:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96934:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96940:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-96980:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97027:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97063:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97072:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97073:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97116:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97127:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97128:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97129:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97219:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97224:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97225:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97226:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97309:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97314:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97315:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97316:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97404:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97405:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97406:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97407:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97432:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97451:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97456:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97460:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97611:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97647:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97648:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97649:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97695:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97696:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97697:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97699:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97802:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97803:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97804:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97845:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97889:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97890:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97891:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97892:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97982:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97984:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97985:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-97986:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98046:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98083:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98087:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98088:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98171:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98175:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98176:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98177:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98220:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98221:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98222:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98223:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98316:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98317:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98318:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98358:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98403:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98405:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98407:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98408:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98494:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98495:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98496:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98497:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98544:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98581:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98587:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98588:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98693:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98694:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98706:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98707:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98759:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98760:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98763:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98767:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98877:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98879:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98921:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98922:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98967:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98968:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98978:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-98979:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99066:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99069:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99070:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99071:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99164:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99165:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99166:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99167:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99253:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99255:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99261:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99262:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99305:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99306:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99315:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99347:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99427:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99464:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99474:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99477:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99561:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99562:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99563:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99564:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99707:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99708:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99709:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99710:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99760:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99761:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99801:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99802:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99890:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99891:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99892:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99893:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99939:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99941:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99942:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-99943:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-136:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-137:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-138:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-178:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-223:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-224:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-225:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-226:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-313:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-315:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-316:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-317:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-367:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-372:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-412:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-413:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-504:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-514:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-516:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-517:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-578:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-580:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-581:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-582:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-830:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-831:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-832:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-875:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-929:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-930:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-931:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-933:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1026:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1027:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1028:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1030:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1093:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1094:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1139:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1143:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1329:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1370:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1371:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1376:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1430:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1431:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1433:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1434:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1617:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1621:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1626:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1692:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1750:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1751:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1752:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1753:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1840:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1842:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1844:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1845:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1892:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1915:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1981:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-1984:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2061:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2068:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2071:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2072:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2118:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2123:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2125:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2126:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2204:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2220:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2221:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2261:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2310:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2315:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2316:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2317:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2406:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2407:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2409:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2410:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2506:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2516:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2518:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2519:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2604:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2605:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2606:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2607:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrackingCallback] Mean Epoch Time = 34.879443016919225 seconds, Total Train Time = 2605.0954711437225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-2653:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2654:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2655:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n",
      "INFO:p-2695:t-8601880640:config.py:<module>:PyTorch version 2.6.0 available.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.35255715250968933,\n",
       " 'eval_runtime': 31.9955,\n",
       " 'eval_samples_per_second': 43.694,\n",
       " 'eval_steps_per_second': 0.344,\n",
       " 'epoch': 44.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_DIR = \"ttm_finetuned_models/\"\n",
    "\n",
    "print(f\"Using learning rate = {learning_rate}\")\n",
    "finetune_forecast_args = TrainingArguments(\n",
    "    output_dir=os.path.join(OUT_DIR, \"output\"),\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=num_epochs,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=2 * batch_size,\n",
    "    dataloader_num_workers=4,\n",
    "    report_to=None,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    logging_dir=os.path.join(OUT_DIR, \"logs\"),  # Make sure to specify a logging directory\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    "    use_cpu=True,\n",
    ")\n",
    "\n",
    "# Create the early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.0,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "tracking_callback = TrackingCallback()\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(finetune_forecast_model.parameters(), lr=learning_rate)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    learning_rate,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=math.ceil(len(train_dataset) / (batch_size)),\n",
    ")\n",
    "\n",
    "finetune_forecast_trainer = Trainer(\n",
    "    model=finetune_forecast_model,\n",
    "    args=finetune_forecast_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[early_stopping_callback, tracking_callback],\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")\n",
    "\n",
    "# Fine tune\n",
    "finetune_forecast_trainer.train()\n",
    "\n",
    "finetune_forecast_trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf4f10",
   "metadata": {},
   "source": [
    "### Plot the Predictions vs. Actuals\n",
    "\n",
    "Plot the predictions vs. actuals for some random samples of time intervals in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a5fe7-2039-49e6-a47e-7a35254b295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(\n",
    "    model=finetune_forecast_trainer.model,\n",
    "    dset=test_dataset,\n",
    "    plot_prefix=\"test_finetune\",\n",
    "    channel=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forge-granite-tsfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
